# backend/app_ver4.py
import pandas as pd
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from backend.loader import load_model, load_data
from backend.bias_audit import audit_fairness
from backend.explainability import explain_with_shap, explain_with_lime
from backend.drift_detection import detect_data_drift
from backend.robustness import evaluate_robustness

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression

SENSITIVE_KEYWORDS = ['gender', 'sex', 'race', 'ethnicity']

def detect_sensitive_columns(columns):
    return [col for col in columns if any(keyword in col.lower() for keyword in SENSITIVE_KEYWORDS)]

def main():
    print("ğŸ” Smart AI Auditor - Interactive Mode")

    model = load_model()
    df = load_data()

    print(f"\nğŸ“Š Available columns in your data: {list(df.columns)}\n")

    target_col = input("ğŸ¯ Enter the name of the target column (label): ").strip()
    if target_col not in df.columns:
        raise ValueError(f"âŒ Column '{target_col}' not found in data.")

    sensitive_input = input("ğŸ§ª Enter sensitive column(s) (comma-separated) or leave blank for auto-detect: ").strip()
    if sensitive_input:
        sensitive_cols = [col.strip() for col in sensitive_input.split(",")]
        for col in sensitive_cols:
            if col not in df.columns:
                raise ValueError(f"âŒ Sensitive column '{col}' not found in data.")
    else:
        sensitive_cols = detect_sensitive_columns(df.columns)
        print(f"âœ… Auto-detected sensitive columns: {sensitive_cols}" if sensitive_cols else "âš ï¸ No sensitive columns detected.")
    
    X = df.drop(columns=[target_col])
    y_true = df[target_col]
    y_pred = model.predict(X)

    print("âœ… Model prediction complete.\n")

    # Fairness
    for col in sensitive_cols:
        print(f"\nğŸ“‹ Running fairness audit for: '{col}'")
        results = audit_fairness(y_true, y_pred, sensitive_features=X[col])
        interp = results["fairness_interpretation"]

        print("\nğŸ“Š Fairness Metrics")
        print(f"â–ª Overall Accuracy              : {results['overall_accuracy']:.4f}")
        print(f"â–ª Accuracy by Group            : {results['accuracy_by_group']}")
        print(f"â–ª Selection Rate by Group      : {results['selection_rate_by_group']}")
        print(f"â–ª Accuracy Disparity           : {interp['accuracy_disparity']:.4f}")
        print(f"â–ª Selection Rate Disparity     : {interp['selection_rate_disparity']:.4f}")
        print(f"â–ª Equalized Odds Difference    : {interp['equalized_odds_difference']:.4f}")

        print("\nğŸ“˜ Metric Definitions:")
        print("â€¢ Accuracy Disparity: Difference in accuracy between best and worst performing groups. Ideal < 0.1")
        print("â€¢ Selection Rate Disparity: Difference in selection (positive prediction) rates across groups. Ideal < 0.1")
        print("â€¢ Equalized Odds Difference: Measures difference in error rates (false pos/neg) between groups. Ideal â‰ˆ 0")

        print(f"\nğŸ” Final Verdict: {interp['notes']}\n")

    # Explainability
    print("\nğŸ§  Explainability (SHAP & LIME)")
    sample = X.iloc[[0]]
    print("\nğŸ“Œ Explaining prediction for first instance:")

    if isinstance(model, (RandomForestClassifier, GradientBoostingClassifier)):
        print("\nğŸ” SHAP Explanation for Sample #1:")
        explain_with_shap(model, sample)
    else:
        print("âš ï¸ SHAP not applicable: Model is not tree-based.")

    if isinstance(model, (LogisticRegression, RandomForestClassifier)):
        print("\nğŸ” LIME Explanation for Sample #1:")
        explain_with_lime(model, X, sample)
    else:
        print("âš ï¸ LIME not applicable: Only supported for LogisticRegression or RandomForest.")

    # Drift Detection
    print("\nğŸ“¦ Data Drift Detection")
    ref_path = input("ğŸ“ Enter path to reference data CSV (e.g., 'data/reference_data.csv'): ").strip()
    if not os.path.exists(ref_path):
        print("âŒ Reference data path not found. Skipping drift check.")
    else:
        reference_data = pd.read_csv(ref_path)
        drift_results = detect_data_drift(reference_data, X)

        print("\nğŸ“Š Drift Summary:")
        print(f"â–ª Drift Score        : {drift_results['drift_score']:.4f}")
        print(f"â–ª Drift Detected     : {drift_results['drift_detected']}")
        print(f"â–ª Notes              : {drift_results['notes']}")

        for feature, stats in drift_results["feature_stats"].items():
            print(f"  â€¢ {feature}: Drifted={stats['drifted']}, KS_p={stats['ks_p_value']:.4f}, JS Divergence={stats['js_divergence']:.4f}")

    # Robustness
    print("\nğŸ§ª Model Robustness Evaluation")
    robustness_results = evaluate_robustness(model, X, y_true)

    if "error" in robustness_results:
        print(f"âŒ Robustness check skipped: {robustness_results['error']}")
    else:
        print(f"â–ª Original Accuracy     : {robustness_results['original_accuracy']:.4f}")
        print(f"â–ª Noisy Accuracy        : {robustness_results['noisy_accuracy']:.4f}")
        print(f"â–ª Accuracy Drop         : {robustness_results['accuracy_drop']:.4f}")
        print(f"â–ª Notes                 : {robustness_results['notes']}")

if __name__ == "__main__":
    main()
